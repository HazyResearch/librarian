#!/usr/bin/env python
# librarian-publish -- publish a data set
# 
# Usage example:
# > librarian publish --project memex --name "First shipment of basic attributes" /lfs/local/0/mjc/foo/bar.csv
#

# TODO support Google Cloud Storage later
from storage_s3 import upload
from metadata_rds import insert_dataset
import argparse, sys, os

parser = argparse.ArgumentParser()
parser.add_argument('local_path', nargs='+')
parser.add_argument('--project', required=True)
parser.add_argument('--name',    required=True)
parser.add_argument('--type',    required=True, choices=['incoming', 'outgoing'])
parser.add_argument('--comment')
args = parser.parse_args()

print >>sys.stderr, args

# sanitize args
if not os.path.exists(args.local_path):
    raise Exception('Invalid path')

# TODO decide remote path from project and name
# done inside storage_s3.upload
project = args.project
name = args.name

# upload given files to AWS S3 or GCS
remote_path = upload(args.local_path, project)

if remote_path is None:
    raise Exception('Something went wrong. Please try again.')

# finally, insert a record into Librarian's database
insert_dataset(remote_path=remote_path, **args)

